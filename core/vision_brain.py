import cv2
import json
import time
import numpy as np
import pyrealsense2 as rs
from google import genai
from google.genai import types

class VisionBrain:
    def __init__(self, api_key):
        print("ğŸ‘ï¸ [Vision] Gemini Robotics (Unified Monitor) ë¡œë”© ì¤‘...")
        self.client = genai.Client(api_key=api_key)
        
        # ì¹´ë©”ë¼ì™€ ì‹¤ì œ ê·¸ë¦¬í¼/ì¤‘ì‹¬ ê°„ì˜ ë¯¸ì„¸ ì˜¤ì°¨ ë³´ì •ê°’ (í•„ìš” ì‹œ ìˆ˜ì •)
        self.OFFSET_X = 0 
        self.OFFSET_Y = 0
        
        # ë¦¬ì–¼ì„¼ìŠ¤ ì„¤ì •
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        # 640x480 í•´ìƒë„, 30í”„ë ˆì„ ì„¤ì •
        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        try:
            # ì¹´ë©”ë¼ ì‹œì‘ (íƒ€ì„ì•„ì›ƒ ë°©ì§€ ë¡œì§ í¬í•¨)
            self.profile = self.pipeline.start(self.config)
            
            # ê¹Šì´ ì„¼ì„œ ìŠ¤ì¼€ì¼ ê°’ ê°€ì ¸ì˜¤ê¸° (ê±°ë¦¬ ì •ë°€ ê³„ì‚°ìš©)
            depth_sensor = self.profile.get_device().first_depth_sensor()
            self.depth_scale = depth_sensor.get_depth_scale()
            
            print("âœ… [Vision] RealSense ì—°ê²° ì„±ê³µ! ëª¨ë‹ˆí„°ë§ ì°½ì„ ë„ì›ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ [Vision] ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.pipeline = None

    def capture_and_detect(self, target_name):
        """
        í™”ë©´ì„ ìº¡ì²˜í•˜ê³ , Geminiì—ê²Œ target_nameì˜ ìœ„ì¹˜ë¥¼ ë¬¼ì–´ë´…ë‹ˆë‹¤.
        ë™ì‹œì— 'HeroBot Monitor' ì°½ì— ë³´ëŠ” í™”ë©´ì„ ë„ì›ë‹ˆë‹¤.
        """
        if not self.pipeline: 
            print("âŒ ì¹´ë©”ë¼ íŒŒì´í”„ë¼ì¸ ì—†ìŒ")
            return None

        try:
            # 1. í”„ë ˆì„ íšë“ (ìµœëŒ€ 3ì´ˆ ëŒ€ê¸°, ì‘ë‹µ ì—†ìœ¼ë©´ íŒ¨ìŠ¤)
            frames = self.pipeline.wait_for_frames(timeout_ms=3000)
            depth_frame = frames.get_depth_frame()
            color_frame = frames.get_color_frame()
            
            if not depth_frame or not color_frame: 
                return None

            # 2. ì´ë¯¸ì§€ ë³€í™˜ (Numpy ë°°ì—´í™”)
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            
            # ê¹Šì´ ì´ë¯¸ì§€ë¥¼ ëˆˆìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¬ë§µ(Heatmap)ìœ¼ë¡œ ë³€í™˜
            # ê°€ê¹Œìš¸ìˆ˜ë¡ ë¶‰ì€ìƒ‰/íŒŒë€ìƒ‰ ë“±ìœ¼ë¡œ í‘œí˜„ë¨
            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

            # ---------------------------------------------------------
            # â˜… [ëª¨ë‹ˆí„°ë§] ë¶„ì„ ì „, í˜„ì¬ í™”ë©´ì„ ë¨¼ì € ë³´ì—¬ì¤Œ (ì‚¬ìš©ì í”¼ë“œë°±ìš©)
            # ---------------------------------------------------------
            # ì™¼ìª½: ì»¬ëŸ¬ í™”ë©´ / ì˜¤ë¥¸ìª½: ê¹Šì´ í™”ë©´ (ê°€ë¡œë¡œ í•©ì¹˜ê¸°)
            monitor_img = np.hstack((color_image, depth_colormap))
            
            # í™”ë©´ì— í…ìŠ¤íŠ¸ ì¶”ê°€ (í˜„ì¬ ì°¾ëŠ” ë¬¼ê±´)
            cv2.putText(monitor_img, f"Searching: {target_name}...", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            cv2.imshow('HeroBot Monitor', monitor_img)
            cv2.waitKey(1) # í™”ë©´ ê°±ì‹ ì„ ìœ„í•´ í•„ìˆ˜ (1ms ëŒ€ê¸°)

            h, w, _ = color_image.shape

            # 3. Geminiì—ê²Œ ì •ë°€ ë¶„ì„ ìš”ì²­
            print(f"   ğŸ§  [Vision] '{target_name}' ìœ„ì¹˜ ì¶”ë¡  ì¤‘...", end="", flush=True)
            
            # OpenCV ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ì¸ì½”ë”©
            _, img_bytes = cv2.imencode('.jpg', color_image)
            
            # â˜… ëª¨ë¸ëª…: ìµœì‹  ì¢Œí‘œ ì¸ì‹ìš© ëª¨ë¸ (Gemini 2.0 Flash Exp ì¶”ì²œ)
            # ë§Œì•½ ì—ëŸ¬ê°€ ë‚˜ë©´ 'gemini-1.5-flash'ë¡œ ë³€ê²½í•˜ì„¸ìš”.
            MODEL_NAME = "gemini-2.0-flash-exp"
            
            # í”„ë¡¬í”„íŠ¸: ì¢Œí‘œ(Point)ë¥¼ ìš”ì²­í•˜ëŠ” ì „ë¬¸ í”„ë¡¬í”„íŠ¸
            prompt = f"""
            Find the '{target_name}' in the image.
            
            [Strict Rules]
            1. You must be highly confident. Do NOT mistake shadows or similar objects.
            2. If you are not sure, return [].
            3. If found, return JSON: [{{"point": [y, x], "label": "{target_name}", "confidence": 0.0-1.0}}]
            4. The point coordinates [y, x] must be normalized between 0 and 1000.
            """
            
            response = self.client.models.generate_content(
                model=MODEL_NAME,
                contents=[
                    types.Part.from_bytes(data=img_bytes.tobytes(), mime_type='image/jpeg'),
                    prompt
                ],
                config=types.GenerateContentConfig(
                    temperature=0.0, 
                    response_mime_type="application/json"
                )
            )
            
            # ì‘ë‹µ íŒŒì‹±
            text = response.text.strip()
            # ê°€ë” ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ì´ ì„ì—¬ì˜¬ ë•Œ ì œê±°
            if text.startswith("```json"): text = text[7:]
            if text.endswith("```"): text = text[:-3]
            
            results = json.loads(text)
            
            if not results:
                print(" âŒ ì—†ìŒ")
                return None
            
            # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì‚¬ìš©
            target = results[0]
            confidence = target.get('confidence', 0.0) 
            
            # ì‹ ë¢°ë„ ì»· (70% ë¯¸ë§Œì€ ë¬´ì‹œ)
            if confidence < 0.7:
                print(f" âš ï¸ ë°œê²¬í–ˆìœ¼ë‚˜ ë¶ˆí™•ì‹¤ ({confidence*100:.0f}%) -> ë¬´ì‹œ")
                return None

            # 4. ì¢Œí‘œ ê³„ì‚° ë° ê±°ë¦¬ ì¸¡ì •
            # GeminiëŠ” [y, x] ìˆœì„œë¡œ 0~1000 ì •ê·œí™” ì¢Œí‘œë¥¼ ì¤Œ
            norm_y, norm_x = target['point']
            
            # ì‹¤ì œ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
            cam_x = int((norm_x / 1000.0) * w)
            cam_y = int((norm_y / 1000.0) * h)
            
            # ê¹Šì´ ì¸¡ì • ì¢Œí‘œ ë³´ì • (ì¹´ë©”ë¼ ì˜¤ì°¨ ë³´ì •ê°’ ì ìš©)
            depth_x = max(0, min(cam_x + self.OFFSET_X, 639))
            depth_y = max(0, min(cam_y + self.OFFSET_Y, 479))
            
            # ê±°ë¦¬ ì¸¡ì • (ë¯¸í„° ë‹¨ìœ„)
            dist = depth_frame.get_distance(depth_x, depth_y)
            
            # ê±°ë¦¬ ì˜ˆì™¸ ì²˜ë¦¬ (0ì´ë©´ ì¸¡ì • ë¶ˆê°€, 2.0m ì´ìƒì´ë©´ ë„ˆë¬´ ë©‚)
            if dist == 0 or dist > 2.5:
                 # 0ì¼ ê²½ìš° ì£¼ë³€ í”½ì…€ í‰ê· ì„ ë‚´ê±°ë‚˜, ê·¸ëƒ¥ ì—ëŸ¬ ì²˜ë¦¬
                 print(f" âš ï¸ ê±°ë¦¬ ì¸¡ì • ì‹¤íŒ¨ ({dist:.2f}m) -> ì¬ì‹œë„ í•„ìš”")
                 return None

            print(f" âœ¨ í™•ì •! ({confidence*100:.0f}%, ê±°ë¦¬: {dist:.2f}m)")
            
            # 5. [ì‹œê°í™”] ì°¾ì€ ê²°ê³¼ë¥¼ í™”ë©´ì— ê·¸ë¦¬ê¸°
            # (1) ì´ˆë¡ìƒ‰ ì  ì°ê¸°
            cv2.circle(color_image, (cam_x, cam_y), 10, (0, 255, 0), -1)
            # (2) í…ìŠ¤íŠ¸ í‘œì‹œ
            label_text = f"{target_name} ({dist:.2f}m)"
            cv2.putText(color_image, label_text, (cam_x + 15, cam_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # (3) Depth í™”ë©´ì—ë„ ì  ì°ì–´ì„œ ìœ„ì¹˜ í™•ì¸
            cv2.circle(depth_colormap, (depth_x, depth_y), 10, (0, 0, 255), -1)
            
            # â˜… ì—…ë°ì´íŠ¸ëœ ê²°ê³¼ í™”ë©´ ë³´ì—¬ì£¼ê¸°
            final_monitor = np.hstack((color_image, depth_colormap))
            cv2.imshow('HeroBot Monitor', final_monitor)
            cv2.waitKey(1)
            
            return {"found": True, "x": cam_x, "y": cam_y, "dist": dist}

        except Exception as e:
            print(f" âš ï¸ ë¹„ì „ ë¶„ì„ ì¤‘ ì—ëŸ¬: {e}")
            return None

    def close(self):
        """ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.pipeline:
            self.pipeline.stop()
        cv2.destroyAllWindows()
        print("ğŸ‘ï¸ [Vision] ì¹´ë©”ë¼ ì¢…ë£Œë¨.")